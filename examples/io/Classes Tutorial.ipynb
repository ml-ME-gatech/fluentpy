{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22af1afa",
   "metadata": {},
   "source": [
    "# IO Classes\n",
    "This notebook shows basic use cases for the io classes. Most classes inherit from base FluentFile, and all make use of pythons context managment- this means that the \"with PythonObject as instance:\" syntax is required to read files. For more on context managment:\n",
    "\n",
    "https://www.geeksforgeeks.org/context-manager-in-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a17e2e",
   "metadata": {},
   "source": [
    "### ReportFileOut\n",
    "the report file out is intended to read files created by \"report variables\" in Fluent. These typically have a '.out' extension and the default naming is report-file-0.out. The ReportFileOut, like many files has a \"readdf\" method which will read the contents of the file into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7ba163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 cs-htc     cs-temp     max-temp          p-in\n",
      "Iteration                                                     \n",
      "1             -0.514973  521.666480   522.494202  9.770612e+06\n",
      "2             -0.072330  573.833122   574.603027  9.772086e+06\n",
      "3             -0.032154  631.216434   632.006836  9.773973e+06\n",
      "4             -0.057291  694.338079   695.151062  9.775655e+06\n",
      "5             -0.071804  763.771889   764.609741  9.776419e+06\n",
      "...                 ...         ...          ...           ...\n",
      "817        13273.865069  837.622352  1202.924316  9.782954e+06\n",
      "818        13273.882725  837.622031  1202.923828  9.782954e+06\n",
      "819        13273.902107  837.621659  1202.923462  9.782954e+06\n",
      "820        13273.918909  837.621313  1202.923096  9.782954e+06\n",
      "821        13273.936812  837.620960  1202.922607  9.782954e+06\n",
      "\n",
      "[821 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from wbfluentpy.io.classes import ReportFileOut\n",
    "import os\n",
    "data_folder = 'data_files'\n",
    "\n",
    "with ReportFileOut(os.path.join(data_folder,'report-file-0.out')) as rfile:\n",
    "    df = rfile.readdf()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7aa4e0",
   "metadata": {},
   "source": [
    "### SolutionFile\n",
    "\n",
    "The solution file class handles reading solution files created in Fluent. Solution files are transcripts, essentially recordings of the convergence activity of the numerical solution. These files have \".trn\" extension with a default naming of \"Solution.trn\"\n",
    "\n",
    "Solution files reading handles missing data by filling gaps with NaN. the size of the dataframe will be the total number of iterations, and any variable that begins later, or is reported at irregular intervals with be filled with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13426920",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "no columns found in solution file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - Georgia Institute of Technology\\Desktop\\repository\\wbfluentpy\\io\\classes.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\s+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msolution_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meol1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\more_itertools\\more.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f91b4da70f30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#the first file here has no iterations, this will cause an AttributeError to be raised - left to the user to be handled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mSolutionFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Solution.trn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreaddf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Georgia Institute of Technology\\Desktop\\repository\\wbfluentpy\\io\\classes.py\u001b[0m in \u001b[0;36mreaddf\u001b[1;34m(self, skiprows, nrows)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \"\"\"\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[0mcleaned_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;31m#hope that you can convert the text - deals with (or tries to) deal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[1;31m#with recorded data with inconsistent reporting width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Georgia Institute of Technology\\Desktop\\repository\\wbfluentpy\\io\\classes.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1014\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\s+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msolution_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meol1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no columns found in solution file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: no columns found in solution file"
     ]
    }
   ],
   "source": [
    "from wbfluentpy.io.classes import SolutionFile\n",
    "\n",
    "#the first file here has no iterations, this will cause an AttributeError to be raised - left to the user to be handled\n",
    "with SolutionFile(os.path.join(data_folder,'Solution.trn')) as sfile:\n",
    "    df = sfile.readdf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1331f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with SolutionFile(os.path.join(data_folder,'Solution-2.trn')) as sfile:\n",
    "    df = sfile.readdf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e7be5",
   "metadata": {},
   "source": [
    "### PostDataFile\n",
    "The PostDataFile reads data outputted from CFD post. The PostDataFile class can be treated as above by reading a single dataframe, or as a dictionary, reading multiple data frames if there are multiple surfaces in the post file. the PostDataFile works with multiple variable export, and assigns the keys of the dictionaries based on the names of the surfaces. These files usually have a .csv extension. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wbfluentpy.io.classes import PostDataFile\n",
    "\n",
    "with PostDataFile(os.path.join(data_folder,'yplus_and_htc_data.csv')) as pdfile:\n",
    "    pdfile.readdf()\n",
    "    \n",
    "for key in pdfile.keys(): \n",
    "    print('Surface: {}'.format(key))\n",
    "    print('Columns')\n",
    "    print(pdfile[key].columns)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287b5b9",
   "metadata": {},
   "source": [
    "### XYDataFile\n",
    "The XYDataFile is designed to work with files exported from the \"XY Plots\" in Fluent. This is fairly similar to the format of PostDataFile with the representation of multiple data in a dictionary type manner. This does not handle missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wbfluentpy.io.classes import XYDataFile\n",
    "\n",
    "with XYDataFile(os.path.join(data_folder,'temp40HF.xy')) as xydfile:\n",
    "    xydfile.readdf()\n",
    "    \n",
    "for key in xydfile.keys():\n",
    "    print(key)\n",
    "    print(xydfile[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479c0f4",
   "metadata": {},
   "source": [
    "### SurfacePointFile\n",
    "the surface point file is meant for creating _and_ reading the results of surface points in Fluent. Points fall under the general category of \"surfaces\" in Fluent and are useful for extracting information from locations. The class only permits 3D data. The interface for creating input into fluent is through the classmethod \"write_fluent_input_from_table\" which takes arguments of \n",
    "\n",
    "X - the coordinates of the points, as a n x 3 size array\n",
    "file_name: the file name to write the file to, as a string\n",
    "export_variables: either a string or a list of strings of field variables we want to sample at the points \n",
    "\n",
    "The reading methods contain the standard readdf() method, which reads in the file. the method get_point_surface_data will read in the DataFrame, but will index the points based upon their position in the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593d6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wbfluentpy.io.classes import SurfacePointFile\n",
    "import numpy as np\n",
    "\n",
    "#creation of surface point file\n",
    "X = np.linspace(0,1,10)[:,None]\n",
    "X = np.concatenate([X,X,X],axis = 1)\n",
    "\n",
    "#create input into Fluent\n",
    "spf = SurfacePointFile.write_fluent_input_from_table(X,'surface_point_file','temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading output of a surface point file\n",
    "from wbfluentpy.io.classes import SurfacePointFile\n",
    "\n",
    "with SurfacePointFile(os.path.join(data_folder,'point_input.psf.out')) as spf:\n",
    "    df = spf.readdf()\n",
    "    print(df)\n",
    "    df = spf.get_point_surface_data()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a853771",
   "metadata": {},
   "source": [
    "### SphereSliceFile\n",
    "## WARNING: THIS CLASS IS UNDER ACTIVE DEVELOPMENT AND IS NOT RETURNING CORRECT RESULTS AS OF 11.20.2021\n",
    "\n",
    "The SphereSliceFile is very similar to the SurfacePointFile, however it works with spheres rather than single points. Spheres consists of a list of datapoints rather than a single coordinates, and thus are slighlty more complicated to deal with. They also require specification of a radius in addition to their coordinates for input creation\n",
    "\n",
    "In addition to the standard \"readdf()\" method, this class also contains the method get_sphere_surface_data(operator) where operator must be a callable that operates on the data of the sphere, for example: np.mean,np.max,np.min,np.median. This returns the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c801ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [sphere-slice, sphere-0, 0.0, 0.0, 0.0, 0.01, sphere-slice, sphere-1, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.01, sphere-slice, sphere-2, 0.2222222222222222, 0.2222222222222222, 0.2222222222222222, 0.01, sphere-slice, sphere-3, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.01, sphere-slice, sphere-4, 0.4444444444444444, 0.4444444444444444, 0.4444444444444444, 0.01, sphere-slice, sphere-5, 0.5555555555555556, 0.5555555555555556, 0.5555555555555556, 0.01, sphere-slice, sphere-6, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.01, sphere-slice, sphere-7, 0.7777777777777777, 0.7777777777777777, 0.7777777777777777, 0.01, sphere-slice, sphere-8, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888, 0.01, sphere-slice, sphere-9, 1.0, 1.0, 1.0, 0.01, q, file/export/ascii, sphere_slice_file.out, sphere-0, sphere-1, sphere-2, sphere-3, sphere-4, sphere-5, sphere-6, sphere-7, sphere-8, sphere-9, yes, temperature, velocity, yes]\n",
      "\n",
      "[77 rows x 0 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 75: expected 1 fields, saw 2\\nSkipping line 79: expected 1 fields, saw 2\\n'\n"
     ]
    }
   ],
   "source": [
    "from wbfluentpy.io.classes import SphereSliceFile\n",
    "\n",
    "#create input for fluent\n",
    "R = np.ones_like(X.shape[0])*1e-2\n",
    "ssf = SphereSliceFile.write_fluent_input_from_table(X,R,'sphere_slice_file',['temperature','velocity'])\n",
    "\n",
    "#read output from fluent\n",
    "\n",
    "with SphereSliceFile(os.path.join(data_folder,'sphere.ssf.out')) as nssf:\n",
    "    df = nssf.readdf()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281d18ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824, 4)\n",
      "    y-coordinate  z-coordinate  temperature\n",
      "0      -0.000187     -0.000187   347.588209\n",
      "1      -0.000176     -0.000176   468.205012\n",
      "2      -0.000122     -0.000122   333.660848\n",
      "3      -0.000121     -0.000121   441.438598\n",
      "4      -0.000123     -0.000123   328.415587\n",
      "5      -0.000123     -0.000123   413.743855\n",
      "6      -0.000187     -0.000187   327.376457\n",
      "7      -0.000188     -0.000188   390.075094\n",
      "8      -0.000187     -0.000187   324.044867\n",
      "9      -0.000189     -0.000189   383.076113\n",
      "10     -0.000187     -0.000187   319.934659\n",
      "11     -0.000188     -0.000188   374.363584\n",
      "12     -0.000123     -0.000123   317.911928\n",
      "13     -0.000125     -0.000125   364.452954\n",
      "14     -0.000117     -0.000117   312.499126\n",
      "15     -0.000117     -0.000117   356.311973\n",
      "16     -0.000187     -0.000187   309.018169\n",
      "17     -0.000182     -0.000182   348.888066\n"
     ]
    }
   ],
   "source": [
    "#read output from fluent\n",
    "from wbfluentpy.io.classes import SphereSliceFile\n",
    "import numpy as np\n",
    "import os\n",
    "data_folder = 'data_files'\n",
    "\n",
    "with SphereSliceFile(os.path.join(data_folder,'sphere.ssf.out')) as nssf:\n",
    "    df = nssf.readdf()\n",
    "    print(df.shape)\n",
    "    df = nssf.get_sphere_surface_data(np.mean)\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e3e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
